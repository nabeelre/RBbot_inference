{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04932b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from architectures import DANN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d884e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"RBbot_old.pth\", map_location=torch.device('cpu'))\n",
    "model = model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "torch.save(model.state_dict(), 'RBbot_new.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f268d713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6efe627",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model_name\": \"DANN\",\n",
    "    \"learning_rate\": 1e-06,\n",
    "    \"source_batch_size\": 64,\n",
    "    \"target_batch_size\": 256,\n",
    "    \"epochs\": 500,\n",
    "    \"image_size\": 41,\n",
    "    \"random_seed\": 2,\n",
    "    \"figs_every_epoch\": 1,\n",
    "    \"num_domains\": 2,\n",
    "    \"source_dataset_kind\": \"ZTF\",\n",
    "    \"source_dataset_variant\": \"m6\",\n",
    "    \"target_dataset_kind\": \"DECam\",\n",
    "    \"target_dataset_variant\": \"m3\",\n",
    "    \"conv_kernel\": 3,\n",
    "    \"conv1_channels\": 32,\n",
    "    \"conv1_dropout\": 0.25,\n",
    "    \"conv2_channels\": 32,\n",
    "    \"conv2_dropout\": 0.25,\n",
    "    \"class1_neurons\": 64,\n",
    "    \"class1_dropout\": 0.25,\n",
    "    \"class2_neurons\": 64,\n",
    "    \"class2_dropout\": 0.25,\n",
    "    \"class3_neurons\": 64,\n",
    "    \"class3_dropout\": 0.25,\n",
    "    \"domain1_neurons\": 64,\n",
    "    \"testing\": 0,\n",
    "    \"run_name\": \"quiet-shadow-131\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41c797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(config):\n",
    "    \n",
    "    model = DANN(config)\n",
    "    model.load_state_dict(torch.load('RBbot_new.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29a21cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(config)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a26a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a668e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('RBbot_old.pth', map_location=torch.device('cpu'))\n",
    "model = model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571a923c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45731621",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(10, 3, 41, 41).to(device)  # Example input\n",
    "\n",
    "raw_preds, _ = model(input_data=input_tensor, lamb=1)\n",
    "preds = torch.round(raw_preds.detach())\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cfcb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kind = config['source_dataset_kind']\n",
    "dataset_variant = config['source_dataset_variant']\n",
    "image_size = config['image_size']\n",
    "\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from RBbot.DANN.utils import CustomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import RBbot.alert_utils\n",
    "\n",
    "batch_size = config['target_batch_size']\n",
    "\n",
    "triplets_path = f\"/Users/nabeelr/Desktop/School/LS4/RBbot/RBbot/data/{dataset_kind}/val_triplets_{dataset_variant}.npy\"\n",
    "labels_path = f\"/Users/nabeelr/Desktop/School/LS4/RBbot/RBbot/data/{dataset_kind}/val_cand_{dataset_variant}.csv\"\n",
    "labels = pd.read_csv(labels_path, index_col=None)['label']\n",
    "\n",
    "triplets = np.load(triplets_path)\n",
    "if np.shape(triplets)[-1] != image_size:\n",
    "    triplets = RBbot.alert_utils.crop_triplets(triplets, image_size)\n",
    "triplets = torch.from_numpy(triplets)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToDtype(torch.float32)\n",
    "])\n",
    "\n",
    "dataset = CustomDataset(\n",
    "    data=triplets, labels=labels, transform=transform\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "data_target_iter = iter(dataloader)\n",
    "len_dataloader = len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "n_total = 0\n",
    "n_correct = 0\n",
    "all_raw_preds = np.array(())\n",
    "all_labels = np.array(())\n",
    "\n",
    "# For each batch...\n",
    "while batch_idx < len_dataloader:\n",
    "    # Get next batch of data\n",
    "    batch_data = next(data_target_iter)\n",
    "    trips, labels = batch_data\n",
    "    trips = trips.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # The last batch is a different size to make sure all examples are seen\n",
    "    # Not necessary during training\n",
    "    cur_batch_size = len(labels)\n",
    "\n",
    "    # Run model\n",
    "    raw_preds, _ = model(input_data=trips, lamb=1)\n",
    "\n",
    "    # Convert raw scores to rb class predictions\n",
    "    preds = torch.round(raw_preds.detach())\n",
    "\n",
    "    # Compute number of correct examples\n",
    "    n_correct += preds.eq(labels.detach().view_as(preds)).cpu().sum()\n",
    "    n_total += cur_batch_size\n",
    "\n",
    "    # Store quantities for diagnostics later\n",
    "    all_raw_preds = np.concatenate((all_raw_preds, raw_preds.detach().cpu().numpy()))\n",
    "    all_labels = np.concatenate((all_labels, labels.cpu().numpy()))\n",
    "\n",
    "    batch_idx += 1\n",
    "\n",
    "print(n_correct / n_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f7c8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cfaa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f0fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = np.load(\"ZTF_exs.npy\")\n",
    "\n",
    "# Convert numpy array triplets to pytorch tensor and put them on the device\n",
    "trips_tensor = torch.Tensor(trips).to(device)\n",
    "\n",
    "# Run the model on the triplets\n",
    "output = model(trips_tensor)\n",
    "\n",
    "scores = output[0].detach().cpu().numpy()\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac27eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
